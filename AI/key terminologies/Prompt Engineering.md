"Prompt engineering" refers to the strategic construction and refinement of prompts to elicit specific responses from AI language models, such as GPT (Generative Pre-trained Transformer) models like GPT-3 or similar language generation systems.

In the context of AI, a prompt is a starting point or input provided to an AI model to generate an output. **Prompt engineering involves crafting these prompts in a way that guides the model to produce desired or relevant outputs.** It can involve tweaking the wording, structure, or context of the prompt to achieve different outcomes, such as generating creative text, answering questions, completing tasks, or providing specific information.

Effective prompt engineering requires an understanding of the capabilities and limitations of the AI model being used, as well as knowledge of how to manipulate the input to encourage the desired output. Researchers, developers, and users often experiment with various prompts to optimize the performance of AI models for different applications, tasks, or objectives.

If a business wants to  use a chat bot for customer support, a prompt engineer design's and identifies prompts that produces appropriate outputs. Prompt Engineer also corrects existing vulnerabilities in this program, its the job of prompt engineers to even handle safety.

**Question 1**: Are the prompts what prompt engineers write act as an input feed for the AI model?

Yes, the prompts created by prompt engineers serve as the input for the AI model. These prompts are carefully crafted pieces of text that guide the AI model's generation or response. The quality, structure, and content of these prompts significantly influence the output or responses generated by the AI model.

**Question 2**: If yes? When is this done? At what stage of development  this is done?

Prompt engineering, where engineers design these input prompts, can occur at various stages of AI model development:

**Training Stage:** During the initial training of an AI model, prompt engineering may involve the creation of prompts used to fine-tune the model on specific tasks or datasets. Engineers craft prompts alongside labeled data to guide the model's learning process.

**Fine-Tuning and Optimization:** After the initial training, engineers might continue to refine the prompts used to fine-tune the model further, improve its performance, or adapt it to different applications or domains.

**Application Stage:** When deploying an AI model for a specific task or application, engineers may design prompts tailored to that particular use case. These prompts are the inputs that users provide to the model when they want specific outputs or responses.

**Ongoing Improvement:** Even after deployment, prompt engineers might continue to refine and optimize prompts based on user feedback, changing requirements, or to enhance the model's performance.

In essence, prompt engineering is an iterative process that can happen at different stages of the AI model's development lifecycle. It involves the continuous refinement and creation of prompts to direct the model's behaviour towards generating desired outputs for specific tasks or applications.