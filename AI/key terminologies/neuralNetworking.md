Neural networking, or more commonly referred to as neural networks or artificial neural networks (ANNs), is a subfield of artificial intelligence (AI) and machine learning (ML) inspired by the structure and functioning of biological neural networks in the human brain.

Neural networks are computational models composed of interconnected nodes, called artificial neurons or "neurons," which are organized into layers. 
Each neuron takes input, **performs a computation, and produces an output that is passed to the next layer of neurons**. 
The connections between **neurons are represented by numerical weights**, which determine the strength and significance of the connections.

The fundamental building block of a neural network is the artificial neuron, which typically applies a non-linear activation function to the weighted sum of its inputs. The activation function introduces non-linearity into the network, enabling it to model complex relationships and **make non-linear predictions**.

Neural networks learn from data through a process called training. During training, the network adjusts the weights of its connections based on the input data and the desired output. This adjustment is typically achieved using optimization algorithms, such as gradient descent, which iteratively updates the weights to minimize the difference between the predicted output and the actual output.

Neural networks can have different architectures and structures, including:

1. Feedforward Neural Networks: In this type of network, information flows in a single direction, from input to output layers, without loops or cycles. It is the simplest and most common type of neural network.
    
2. Recurrent Neural Networks (RNNs): RNNs introduce feedback connections, allowing the network to maintain an internal memory or context. This makes them suitable for tasks involving sequential or time-dependent data, such as natural language processing or speech recognition.
    
3. Convolutional Neural Networks (CNNs): CNNs are primarily used for processing grid-like data, such as images or videos. They leverage specialized layers, such as convolutional and pooling layers, to capture spatial hierarchies and patterns in the input data.
    
4. Deep Neural Networks (DNNs): DNNs refer to neural networks with multiple hidden layers between the input and output layers. Deep learning, a subset of machine learning, focuses on training and utilizing deep neural networks to solve complex problems, often achieving superior performance in tasks such as image recognition, natural language processing, and reinforcement learning.

Activation functions :- that are applied on the node to produce different output / different predictions. 
Different nodes can have different activation function